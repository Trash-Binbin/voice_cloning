上期我们讲了卷积
并初步介绍了卷积神经网络
在过去的十年中
他几乎以一己之力
撑起了人工智能的半边天
然而它的内部构造有何神奇
又为何受到了如此多的关注呢
大家好只说人话
专治好奇
我是耿直哥
今天咱们就来聊聊卷积神经网络
凭什么这么香
我们接下来会用一个爱情故事开始
一步步的讲清楚
一为啥要用卷基层
2石化层是干啥的
3全连接层的妙用
4他是怎么牛逼起来的
5未来的改进方向是什么
提起神经网络
你可能会如数家珍地说出CNN LSTM
RBM等变种
如果说神经网络是个黑盒子
吃进去数据
吐出来结果
那么不同神经网络的最大区别
就是肚子里的网络结构
卷积神经网络有什么过人之处呢
废话少说
让我们先钻进他的肚肚里看看
它的英文是convolutional neural network
简称CNN
如果把神经网络比喻成一个小伙子
那卷机就是精明强干的妹子
而卷机神经网络就是二人的合体
为什么这么说呢
别着急
看完这个视频你就彻底明白了
卷积神经网络模型
用常见的节点线段图模型来表示
是这个样子
左边是输入层
可以是文字语音图像
视频等各种数字化信号
最右边是输出层
一般是分类的类别及其概率
比如我们要识别车型
那输入就是车子的图片
输出就是奔驰宝马奥迪等品牌的概率
其内部蕴含着三种不同的网络层
卷积层磁化层和全连接层
多个卷积加磁化结构层层连接
就是卷积神经网络最重要的特点了
别被这些不明觉厉的术语吓到
一会咱就用人话给你讲明白
首先为什么要用卷基层呢
坦率地讲
这玩意儿其实就是一群计算机学者
受生理学家和数学家的启发
硬生生的造出来的
开始算力不行
数据也少
他们只能歪歪一下
后来硬件升级
数据也多了
一试发现效果很不错
就火了
不过其基本思想还是很容易理解的
传统意义上的神经网络长这样
节点表示神经元
连线表示计算关系
每条线都有一个权重
所谓学习或者训练
就是为数据调整权重
也就是吃饭长身体的过程
如果用审美的眼光来看
他就像是一个好吃懒做的大胖子
为什么这么说呢
因为每层节点
都和上一层的所有节点相连
构成所谓的全连接网络
看似密密麻麻
其实荣誉度大
一身肥肉
一点也不结实性感
这种体型常常是吃得多
消化能力差
空有一身赘肉
力气也不大
显得特别笨
用学术语言来说
就是参数众多
难以训练
举个例子
哪怕输入是100*100的小图像
全连阶层的每个神经元
都有1万个权重参数
动不动就会产生过敏和
换言之就是容易吃多了撑出毛病
卷积运算恰恰相反
一个简洁优美的公式就能描述
简直就是一个体态婀娜
精明强干的漂亮妹子
假如生活中
把挑剔的妹子
嫁给看似傻大笨粗的肥宅男
两人之间会碰撞出什么样的火花
大家可以尽情脑
补吧
科学家们正是基于这种思想
让卷心妹子给神经网络减肥
硬是把他生生改造成了高富帅的型男
让我们看看他们是怎么做的呢
上期视频中
我们以二维图像为例
提到了小小的3*3卷积盒
却能起到特征提取的大作用
通过二维离散卷积操作
把全连接变成了一个个小的局部连接
实现了高效的图像特征提取
这些小小的卷积盒
却具备传说中的空间平移不变的特性
简单举例就是对于一张照片
不管你的脸在哪个位置
他都能够找出来
无论图像大小如何
使用卷机操作
每个滑动区域都具有相同的共享权重
如果使用3*3大小的卷机盒
就只需要学习9个参数
从1万个参数变成9个
这是不是像极了挑剔的妹子
管住你的嘴
强迫你养成良好的生活习惯
杜绝一切垃圾食品
只吃经过认真挑选健康有营养的食物
同样饭量下
消化能力当然会显著增强
卷积运算得到的结果
常常被称作特征图feature map
特征图上的每个点
都是由上一层的若干个点共同决定的
比如3*3卷积核时
每个点是由上一个层的9个点决定的
我们就把这9个点叫做这一点的感受
也可以想象一下
网络层数越多
每一点的感受也就越大
而感受也越广阔
就越能够捕捉更大尺寸的特征
一层卷积感觉不过瘾
层层堆叠起来才更好玩
这就是所谓的深度卷积网络
科学家们发现
卷积层数越多
对复杂特征的表达能力越强
几层只是毛毛雨
十层不嫌多
百层千层方可吹吹牛
其实这也很好理解
以图像分类为例
在多层卷积神经网络中
第一层可以表示在特定的位置和角度
是否出现边缘
而第二层
则可以将这些边缘组合成有趣的模式
比如花纹
在第三层中
也许上一层的花纹
能够进一步
汇合成物体特征部位的模式
这样逐级表示下去
就能够学到图像的各种特征了
类比刚才的例子
哪个妹子会只关注你的一顿饭呢
真正的关心一定是周期式的
多尺度的和全面的
除了饮食
她肯定也很关注你的人品
能力等多个方面
谁不想要一个德智体美劳
全面发展的好老公呢
我们说
神经网络之所以能够解决非线性问题
本质上
就是加入了激活函数这一非线性因素
否则就和线性回归区别不大了
卷积神经网络也不例外
科学家们在卷积过后
也加入了激活函数
最常用的是线形整流单元
rectified linear unit
简称RELU函数
它长这个样子
名字听上去很炫吧
其实
就是把特征图上的所有复数都变成0
而正数不变
作为优秀男人的你
应该很好理解这个选择
既然挑剔的卷积女神
都帮你辨别了习惯的好坏
当然要把所有坏的都改掉
让他们变成0嘛
激活激活
受刺激了
脑子肯定要活泛一点
别一根筋
这
就是所谓的非线性激活函数的阵地喽
以上就是卷基层的全部操作了
接下来我们说说更不像人话
的磁化层吧
所谓的磁化
英文是Pulling
翻译的听上去有点晕
本意其实是淤积或者汇聚更贴切些
直白点说就是抓住主要矛盾
忽略次要因素
磁化层把局部多个神经元的输出
组合成下层单个神经元
来减少数据维度
用数学语言描述
就是
在一个小矩阵中找最大值或者平均值
这就是所谓的最大磁化或者平均磁化
运算
局部磁化一般选择2*2的矩阵就够了
卷积层屁股后边跟着一个磁化层
这个操作的目的
是进一步放大主要特征
忽略掉几个像素的偏差
其意义不光能够降低数据纬度
减少训练参数
同时还能够避免所谓的过敏核
也就是别画蛇添足
学过了头
作为男人的你应该懂得
无论什么时候
面对漂亮妹子
一定要努力掌握
主动迎上去
尽量把自己的优点放大一些
细小的缺点蒙混过关就好了嘛
这其实就是铺领磁化层的秘诀
卷积神经网络的最后一层
往往都保留一个全连接层
它把相邻两层的神经元全部交叉相连
与传统的神经网络是一样的
其作用好比从全句出发做最终结论
和前面的卷基层搭班子
形成了先局部再整体的学习结构
卷机加持化多层级练
对输入数据进行多尺度特征提取
和深度学习
这就好比
卷机妹子挑毛病加肥宅男主动自省
的反复上演
曾经臃肿的全连接网络
终于在卷积妹子的调教下瘦身成功
变成了吃的少挣得多学习能力强
思考有深度的
人类高质量男性
这就是卷积神经网络成功的秘诀
明白了CNN的核心思想
让我们来看看他是怎么牛逼起来的
卷积和神经网络的最初相遇
发生在计算机视觉领域
第一个红娘是日本学者福岛邦彦
他受前任
关于生物视觉系统研究的启发
提出了层级化的人工神经网络
即神经认知模型
处理手写字符识别问题
这被认为是卷积神经网络的前身
不过这最多算是
卷积妹子和神经网络第一次牵手
二人真正的合体
是法国学者杨丽坤等人
在1998年提出
基于梯度学习的卷积神经网络算法
Lunite
它被广泛应用于
美国邮政系统的手写数字和字符识别
卷积神经网络的第一次大放异彩
要回溯到2012年
在有计算机视觉界世界杯之称的image
Knight竞赛上
Hinton等人凭借Alex Knight一举夺魁
这个网络的结构和Lunite非常相似
但是更深更大
并且使用了层叠的卷积层来获取特征
超高的识别率
让学术界意识到
卷积对神经网络改造的巨大潜力
之后Google Facebook微软
以及国内的BAT等公司纷纷投入巨资
研究
各种变体的卷积神经网络层出不穷
例如Zfknight通过可视化
展示了卷积神经网络
各层的功能和作用
牛津大学提出了vggnite
采用堆积的小卷积盒替代大的卷积盒
不仅能够增加决策函数的判别性
还能够减少参数量
Google Knight增加了卷积神经网络的宽度
使用1*1卷积降为减少
参数量在多个不同尺寸的卷积盒上
进行卷积后
再聚合rise Knight残插网络
解决了网络模型的退化问题
使得神经网络可以更深
总的来说
卷积神经网络越变越宽
越来越深越来越复杂
就像两个人的爱情一样
越发的浓烈深刻和多元
它的应用也从最初的计算机视觉
快速拓展到语音识别
自然语言处理等领域
进而应用到工程科学的各行各业
但不管怎么变
CEN的核心思想都没有变
那就是利用拳击核的特征提取能力
通过多层级联实现多尺度特征学习
换句话说
就是充分调动拳击妹子的积极性
进而让神经网络这个小伙子
激发出巨大潜力
卷辑和神经网络的爱情故事还在继续
无论你是有志于这个领域的研究
还是想在别人面前装一装深奥
或许可以从下面这些角度思考一番
传统的cn
对于输入形式
卷积盒起点和初始化方法
都没有严格要求
在这些方面都有很大的改进空间
比如有人在用cn做显著性检测时
就是把图像先进行了一把超像素分割
然后把分割后的超像素
作为新的网络输入
传统的cn在进行特征提取时
好比用筛子筛谷子
总认为筛到最后就是精华
其实中间筛出去的东西
也可以好好利用
有人把这种思想用在人脸识别上
取得了很好的效果
另外传统的CNN就是单纯的卷基核
其实也可以用其他类型的矩阵
比如GABOR滤波器小薄荷之
类的也许会有不错的效果
除了网络结构上的改进
在训练算法上也有很大的潜力
比如对非线性激活函数的改进
最初的cn用的是synomoid函数
或者双曲正切函数
后来才改成了real函数
这种做法简单粗暴
但结果却不错
实验说明了一切
未来说不定还有更加有效的函数出现
好了简要回顾这节课的内容
我们以卷机妹子和神经网络小哥
相爱相杀的故事为例
先介绍了cn的三种典型网络结构
用于特征提取
减少训练参数的卷积层
最大化主要特征避免过敏核的磁化层
以及最后面的全连接层
然后我们简要回顾了
卷积神经网络的演变历程
强调了卷积加磁化脊连
实现多尺度特征表达
是CN成功的主要秘诀
最后我们讨论了卷积神经网络
未来可能改进的主要方向
以上就是这期的内容了
如果对你理解卷积神经网络有所帮助
欢迎关注和转发
我是耿直哥
您的支持
将是我们持续创作的最大动力
