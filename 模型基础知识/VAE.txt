AI去水印
脑部马赛克游戏环境的自动理解
无人驾驶的目标检测
这些有意思的AI应用背后
都有一种叫变分字编码器的模型
variational auto encoder
简称VAE
听上去很拗口的名字啊
两分钟给你讲明白
生活中常见的各种数据
无论文本语音还是图像
都存在着大量的冗余信息
理论上来说呢
他们都可以用极少的变量来表示
实现这种思想的方法就是VAE模型了
它在过去的几年中非常的火
我们知道
神经网络最常见的一类任务就是分类
比方说把车分成各种品牌
或者区分花花草草动物类别之类的
从模型结构上看
神经网络的输入层非常的大
通常就是一幅图片
所有像素的向量表示
而输出层呢
一般就是分类的类别
比方说两类问题只有两个神经元
而中间隐藏层则用来捕获各种特征
在讲VE之前
咱们先看看什么是AE auto encoder
也就是自编码器
注意auto在这可不是自动的意思
而是自己训练自己的意思
它和普通神经网络最大的区别在于
由两部分构成
引coder和decoder
输出不再是类别
而是重建后的图像和输入层呢
有相同数量的神经元
你可能觉得很奇怪
为什么需要这样一个
像复印机一样的东西呢
它最大的特点啊
就在于中间隐藏层神经元个数非常少
起到的作用就像瓶口一样
能够把输入进行过滤
特征提取
有点像高度压缩
用很少的变量就能表示
输入数据
当然隐藏层变量也不是越少越好
太少了
重构后的图片就可能会比较模糊
变量越多
重建的图片就越清晰一些
AE的训练
就是通过重建图像
和原始图像之间的误差损失函数
来实现的
这就是自编码器的基本思想了
它演变出了很多有意思的应用
比方刚开始说的去马赛克去水印
AI抠图替换背景等等
AE和传统的压缩算法不太一样
可以认为是一种全新的图像压缩
或者表示方式
比如
谷歌就用它在减少图像下载的流量
先在云端把这些图像进行incoder
然后指传送特征
到了手机上呢
再通过decoder进行重建
这样就极大地节省了传送的流量
好了讲完字编码器
让我们看看什么是变分
字编码器variational auto encoder
variation呢
其实就是指分布
意思是
不再把输入映射到固定的变量上
而是映射到一个分布上
比如混合高斯GMM上
网络模型中的包特奈克
被分解成了两个项链
一个叫做军制项链
一个叫做方差项链
它的损失函数呢
复杂了一些
长这个样子
具体包含了两个部分
第一块是重建损失
这个和自闭码器是一样的
后面这个呢
是KR散度
用来描述学习的分布
和高斯分布之间的相似性
VAE这个看似复杂的模型
在拍touch这样的框架中
其实呢就是简简单单的几句话
定义模型实验参数数据集
然后就开训了
非常容易上手
有意义这两年很火
有了非常多
的应用除了图像压缩
图像降噪也被应用于图像分割
比如自动驾驶中
就常用它把道路场景进行分割
分成不同的感兴趣区域
它还可以用于环境表示
例如Deepman团队啊
就用它来学习3D模拟世界
用latent model来表示潜在空间
这些学习到的特征
很多时候是可以解释的
比如有的变量改变了地板的颜色
有的表示左右转
有的呢表示旋转等等
另外一个VAE最近的发展趋势
就是与强化学习相结合
用来进行环境的潜在空间表示
从高维的观测数据中有效提取特征
通过压缩大量信息
来训练能够理解世界的agent
好了这就是本期内容
我是耿直哥
如果对你有所帮助
欢迎点赞关注转发
咱们下期见
